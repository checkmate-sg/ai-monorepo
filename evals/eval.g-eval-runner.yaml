# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

# Learn more about building a configuration: https://promptfoo.dev/docs/configuration/guide

description: "implements g-eval evaluation method with checkmate"

prompts:
  - "[The source text is not provided, but for context, it is a submission to CheckMate, an information verification service in Singapore. It is either a text message, an image (optionally with a caption), or a link.]"

providers:
  - id: file://runner.ts
    label: "API runner with try catch"
    config:
      method: "POST"
      maxRetries: 3
      retryDelay: 1000

tests: "https://docs.google.com/spreadsheets/d/1JnU9_GmWkww5LZqgUBQVh8ijkrLxhocz6FYef120tIU/edit?gid=1200356343#gid=1200356343"

outputPath:
  - "https://docs.google.com/spreadsheets/d/1JnU9_GmWkww5LZqgUBQVh8ijkrLxhocz6FYef120tIU/edit?gid=2046898546#gid=2046898546"

defaultTest:
  threshold: 0.7
  assert:
    - type: g-eval
      transform: output.en
      weight: 5
      value: |
        Evaluate if the response contains these points:
        ## Expert Pointers ##
        {{expert_pointers}}
        ## End of Expert Pointers ##
        Give a score depending on how many of the expert pointers are contained in the response, but also consider the relative importance of the pointers, which are listed in descending order of importance.

      provider: openai:gpt-4.1

    - type: equals
      weight: 1
      transform: output.isAccessBlocked
      value: "{{expert_is_access_blocked}}"

    - type: equals
      weight: 1
      transform: output.isControversial
      value: "{{expert_is_controversial}}"

    - type: equals
      weight: 1
      transform: output.isVideo
      value: "{{expert_is_video}}"

    - type: equals
      weight: 5
      transform: output.broadCategory
      value: "{{expert_broad_category}}"

    - type: equals
      weight: 0
      transform: output.numRetries
      value: 0
